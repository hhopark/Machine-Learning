"""
이진 분류(Binary Classification)는 둘 중 하나의 선택지 중에서 정답을 고르는 경우
예를들어 학생들이 시험 성적에 따라서 합격, 불합격이 기재된 데이터가 있다고 가정하고, 시험의 커트라인이 공개되지 않았을때
특정 점수를 얻었을때의 합격, 불합격 여부를 판정할 수 있는 모델을 가질 수 있게된다.

직선형으로 값을 예측하는 것은 적합하지않다. S형의 함수를 찾아야한다.
이때 사용되는 함수가 시그모이드 함수(Sigmoid function)이다. 시그모이드 함수도
비용함수(손실함수)와 유사하게 적합한 W(가중치)와 b를 구하는 것이 핵심이다.
0부터 1까지의 값을 가지는데 출력값이 0.5 이상이면 1(True), 0.5이하면 0(False)로 만들어 이진 분류로 사용한다.
"""

#시그모이드(sigmoid function)의 그래프 표현
"""
import numpy as np
import matplotlib.pyplot as plt

def sigmoid(x):
    return 1/(1+np.exp(-x))
x = np.arange(-5.0, 5.0, 0.1)
y = sigmoid(x)
plt.title('Sigmoid Function')
#--------------------------------------------------
#plt.plot(x,y, 'g')
#plt.plot([0,0], [1.0,0.0], ':')
#plt.show()
#시그모이드 함수는 0과 1사이의 값으로 조정하여 반환한다.
#--------------------------------------------------

#--------------------------------------------------
#y1 = sigmoid(0.5*x)
#y2 = sigmoid(x)
#y3 = sigmoid(2*x)

#plt.plot(x, y1, 'r', linestyle='--') # W가 0.5일때
#plt.plot(x, y2, 'g') # W가 1일때
#plt.plot(x, y3, 'b', linestyle='--') # W가 2일때

#plt.show()
# W 값에 따라 경사도가 변한다. W값이 증가할수록 경사도가 높아진다.
#--------------------------------------------------
y1 = sigmoid(x+0.5)
y2 = sigmoid(x+1)
y3 = sigmoid(x+1.5)

plt.plot(x, y1, 'r', linestyle='--')
plt.plot(x, y2, 'g')
plt.plot(x, y3, 'b', linestyle='--')
plt.plot([0,0],[1.0,0.0], ':')
#plt.show()
# b값에 따라 그래프가 수평이동한다.
#--------------------------------------------------
"""

#로지스틱 회귀의 비용 함수(Cost function)
"""
로지스틱 회귀 또한 경사 하강법을 사용하여 가중치 W를 찾아내지만, 비용 함수로는
'평균 제곱 오차'를 사용하지 않는다. 그 이유는 시그모이드 함수에 비용 함수를 평균 제곱 오차로 하여 그래프를 그리면
로컬 미니멈을 최소값으로 잘못인식하여 Cost가 최소가 되는 W를 찾는다는 비용 함수의 목적으로 맞지 않는다.

로지스틱 회귀에서 찾아낸 비용 함수를 크로스 엔트로피(Cross Entorpy)함수라고 한다.
"""

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers

X = np.array([-50,-40,-30,-20,-10,-5,0,5,10,20,30,40,50])
y = np.array([0,0,0,0,0,0,0,0,1,1,1,1,1])

model =Sequential()
model.add(Dense(1, input_dim=1, activation='sigmoid'))
sgd = optimizers.SGD(lr=0.01)
model.compile(optimizer=sgd, loss='binary_crossentropy',
              metrics=['binary_accuracy'])
model.fit(X, y, batch_size=1, epochs=200, shuffle=False)

import matplotlib.pyplot as plt
plt.plot(X, model.predict(X), 'b', X,y, 'k.')
plt.show()
print(model.predict([1,2,3,4,4.5]))
print(model.predict([11,21,31,41,500]))
